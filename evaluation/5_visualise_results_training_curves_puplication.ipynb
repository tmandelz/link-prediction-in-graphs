{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Results\n",
    "This Notebook downloads experiment data from comet-ml and aggregates or visualises them for the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml.api import API\n",
    "import comet_ml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# set default plt figsize to (12,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "# Set default font sizes\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "\n",
    "\n",
    "# Initialize the Comet API with API key\n",
    "api_key = \"GAzEuNsoYVpPXO2ryeTk7C1o7\"\n",
    "api = API(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments_results_data(workspace, project_name, experiment_ids):\n",
    "    # Get the list of experiments in the project\n",
    "    result_data = []\n",
    "    for k, v in experiment_ids.items():\n",
    "        experiment = api.get(workspace=workspace,\n",
    "                             project_name=project_name, experiment=v)\n",
    "        print(experiment.id)\n",
    "        print(experiment.name)\n",
    "        # You can also fetch individual metrics, parameters, etc.\n",
    "        metrics_valid_mrr = experiment.get_metrics([\"valid_mrr\"])\n",
    "        metrics_test_mrr = experiment.get_metrics([\"test_mrr\"])\n",
    "        max_valid_mrr_value = float('-inf')\n",
    "        max_epoch = None\n",
    "\n",
    "        for record in metrics_valid_mrr:\n",
    "            metric_value = float(record['metricValue'])\n",
    "            if metric_value > max_valid_mrr_value:\n",
    "                max_valid_mrr_value = metric_value\n",
    "                max_epoch = record['epoch']\n",
    "\n",
    "        print(f\"Max valid_mrr: {max_valid_mrr_value}, Epoch: {max_epoch}\")\n",
    "        for record in metrics_test_mrr:\n",
    "            if record['epoch'] == max_epoch:\n",
    "                metric_test_mrr_epoch = float(record['metricValue'])\n",
    "                break\n",
    "        print(f\"Max test_mrr: {metric_test_mrr_epoch}, Epoch: {max_epoch}\")\n",
    "\n",
    "        result_data.append({\"name\": k, \"key\": experiment.id, \"max_valid_mrr\": max_valid_mrr_value,\n",
    "                           \"test_mrr\": metric_test_mrr_epoch, \"epoch\": max_epoch})\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def plot_training_curves(df_mrr, title=\"MRR Curves\", visualize_test_mrr=True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if visualize_test_mrr:\n",
    "        sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"test_mrr\"], x=\"epoch\",\n",
    "                     y=\"metricValue\", label=\"test_mrr\", linestyle=\"dashed\", color=\"red\", alpha=0.7)\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"train_mrr\", color=\"green\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"valid_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"valid_mrr\", color=\"blue\")\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MRR')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{title}.pdf\", format='pdf',dpi=5000,bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_curves_loss_auc(df_mrr, title=\"MRR Curves\", y_axis=\"Metrics\", ):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"Train MRR\", color=\"blue\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_rocauc\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"AUROC\", color=\"orange\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"loss_epoch\"], x=\"epoch\",\n",
    "                 y=\"metricValue\", label=\"Negative-Log-\\nLikelihood-Loss\", color=\"green\")\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def get_experiments_data(workspace, project_name, experiment_ids, other_losses=False, epoch_loss=False):\n",
    "    # Get the list of experiments in the project\n",
    "    metrics_data = []\n",
    "    for k, v in experiment_ids.items():\n",
    "        experiment = api.get(workspace=workspace,\n",
    "                             project_name=project_name, experiment=v)\n",
    "        print(experiment.id)\n",
    "        print(experiment.name)\n",
    "        # You can also fetch individual metrics, parameters, etc.\n",
    "        train_mrr = pd.DataFrame(experiment.get_metrics(\"train_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        valid_mrr = pd.DataFrame(experiment.get_metrics(\"valid_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        test_mrr = pd.DataFrame(experiment.get_metrics(\"test_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        train_loss = pd.DataFrame(experiment.get_metrics(\"loss_epoch\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "\n",
    "        if other_losses:\n",
    "            valid_loss = pd.DataFrame(experiment.get_metrics(\"valid_loss\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            test_loss = pd.DataFrame(experiment.get_metrics(\"test_loss\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            metrics = pd.concat(\n",
    "                [train_mrr, valid_mrr, test_mrr, train_loss, valid_loss, test_loss])\n",
    "        elif epoch_loss:\n",
    "            epoch_loss = pd.DataFrame(experiment.get_metrics(\"loss_epoch\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            auc = pd.DataFrame(experiment.get_metrics(\"train_rocauc\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            metrics = pd.concat(\n",
    "                [train_mrr, valid_mrr, test_mrr, epoch_loss, auc])\n",
    "        else:\n",
    "            metrics = pd.concat([train_mrr, valid_mrr, test_mrr, train_loss])\n",
    "        metrics_data.append(\n",
    "            {\"name\": k, \"key\": experiment.id, \"metrics\": metrics})\n",
    "    return metrics_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Models\n",
    "Model data for reference models (gcn and gin, sage) is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN reference':'15813a0135394f5fbf73e376f46b4cf9',\n",
    "                  'GIN reference':'ea2202bee86a4394adbcbc3c48b47ea9',\n",
    "                  'SAGE reference':'90b05358d9ec47a481eb81ba192b1fad'}\n",
    "workspace = \"tmandelz-outlook-com's Organisation\"\n",
    "project_name = \"transfer-learning-link-prediction\"\n",
    "\n",
    "\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids_2 = {'GCN reference 2':'23ddab6f18b34bdaa97fe203614553df',\n",
    "                  'GIN reference 2':'e945a7824ad2499c921a028738067cf0',\n",
    "                  'SAGE reference 2':'830bf7d7d66446f2bbb34d7d7b80c972'}\n",
    "\n",
    "experiment_data_2 = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids_2)\n",
    "results_data_2 = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get best \n",
    "gcn_df = experiment_data[0]['metrics']\n",
    "gcn_df2 = experiment_data_2[0]['metrics'][:-1]\n",
    "gcn_df2.loc[:,\"epoch\"] += gcn_df[\"epoch\"].max()\n",
    "gcn_df = pd.concat([gcn_df,gcn_df2]).reset_index(drop=True)\n",
    "\n",
    "firstepoch_test_mrr_gcn_ref = float(gcn_df[gcn_df['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "\n",
    "valid_max_idx = gcn_df.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gcn_ref = float(gcn_df.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "\n",
    "gin_df = experiment_data[1]['metrics']\n",
    "gin_df2 = experiment_data_2[1]['metrics'][:-1]\n",
    "gin_df2.loc[:,\"epoch\"] += gin_df[\"epoch\"].max()\n",
    "gin_df = pd.concat([gin_df,gin_df2]).reset_index(drop=True)\n",
    "\n",
    "firstepoch_test_mrr_gin_ref = float(gin_df[gin_df['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = gin_df.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gin_ref = float(gin_df.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "\n",
    "sage_df = experiment_data[2]['metrics']\n",
    "sage_df2 = experiment_data_2[2]['metrics'][:-1]\n",
    "sage_df2.loc[:,\"epoch\"] += sage_df[\"epoch\"].max()\n",
    "sage_df = pd.concat([sage_df,sage_df2]).reset_index(drop=True)\n",
    "\n",
    "firstepoch_test_mrr_sage_ref = float(sage_df[sage_df['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = sage_df.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_sage_ref = float(sage_df.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MRR Curves\n",
    "Plot MRR Curves together into a single visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df['metricValue'] = gcn_df['metricValue'].astype(float)\n",
    "gin_df['metricValue'] = gin_df['metricValue'].astype(float)\n",
    "sage_df['metricValue'] = sage_df['metricValue'].astype(float)\n",
    "\n",
    "plot_training_curves(gin_df, \"Reference GCN - MRR Curves\")\n",
    "plot_training_curves(gin_df, \"Reference GIN - MRR Curves\")\n",
    "plot_training_curves(sage_df, \"Reference SAGE - MRR Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning Models\n",
    "Model data for Finetuning models is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN finetune':'0b67c8710eaa4785bfc1579a341a21db',\n",
    "                  'GIN finetune':'f5f2c85520b44bb580881868e07b2d76',\n",
    "                  'SAGE finetune':'dc44f38332824315a070238c399a08fe'}\n",
    "workspace = \"tmandelz-outlook-com's Organisation\"\n",
    "project_name = \"transfer-learning-link-prediction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_val_train_mrr =experiment_data[0]['metrics']\n",
    "df_fine_val_train_mrr = df_fine_val_train_mrr[df_fine_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "np.round(np.mean(np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MRR Curves\n",
    "Plot MRR Curves together into a single visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_fine = experiment_data[0]['metrics']\n",
    "firstepoch_test_mrr_gcn_fine = float(gcn_df_fine[gcn_df_fine['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = gcn_df_fine.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gcn_fine = float(gcn_df_fine.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "\n",
    "gin_df_fine = experiment_data[1]['metrics']\n",
    "firstepoch_test_mrr_gin_fine = float(gin_df_fine[gin_df_fine['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = gin_df_fine.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gin_fine = float(gin_df_fine.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "sage_df_fine = experiment_data[2]['metrics']\n",
    "firstepoch_test_mrr_sage_fine = float(sage_df_fine[sage_df_fine['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = sage_df_fine.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_sage_fine = float(sage_df_fine.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_fine['metricValue'] = gcn_df_fine['metricValue'].astype(float)\n",
    "gin_df_fine['metricValue'] = gin_df_fine['metricValue'].astype(float)\n",
    "sage_df_fine['metricValue'] = sage_df_fine['metricValue'].astype(float)\n",
    "\n",
    "plot_training_curves(gcn_df_fine, \"arXiv CS Finetuning GCN - MRR Curves\")\n",
    "plot_training_curves(gin_df_fine, \"arXiv CS Finetuning GIN - MRR Curves\")\n",
    "plot_training_curves(sage_df_fine, \"arXiv CS Finetuning SAGE - MRR Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Time Differences GCN Reference / Finetune\n",
    "Computing time differences between the reference and finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df['timestamp'] = gcn_df['timestamp']/1000\n",
    "gcn_df['timestamp'] = pd.to_datetime(gcn_df['timestamp'], unit='s')\n",
    "gcn_df['minute_diff'] = (gcn_df['timestamp'] - gcn_df['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "gcn_df_fine['timestamp'] = gcn_df_fine['timestamp']/1000\n",
    "gcn_df_fine['timestamp'] = pd.to_datetime(gcn_df_fine['timestamp'], unit='s')\n",
    "gcn_df_fine['minute_diff'] = (gcn_df_fine['timestamp'] - gcn_df_fine['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "gin_df['timestamp'] = gin_df['timestamp']/1000\n",
    "gin_df['timestamp'] = pd.to_datetime(gin_df['timestamp'], unit='s')\n",
    "gin_df['minute_diff'] = (gin_df['timestamp'] - gin_df['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "gin_df_fine['timestamp'] = gin_df_fine['timestamp']/1000\n",
    "gin_df_fine['timestamp'] = pd.to_datetime(gin_df_fine['timestamp'], unit='s')\n",
    "gin_df_fine['minute_diff'] = (gin_df_fine['timestamp'] - gin_df_fine['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "sage_df['timestamp'] = sage_df['timestamp']/1000\n",
    "sage_df['timestamp'] = pd.to_datetime(sage_df['timestamp'], unit='s')\n",
    "sage_df['minute_diff'] = (sage_df['timestamp'] - sage_df['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "sage_df_fine['timestamp'] = sage_df_fine['timestamp']/1000\n",
    "sage_df_fine['timestamp'] = pd.to_datetime(sage_df_fine['timestamp'], unit='s')\n",
    "sage_df_fine['minute_diff'] = (sage_df_fine['timestamp'] - sage_df_fine['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sage_df[sage_df['metricName'] == \"test_mrr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the reference model was the first time over 10 hours (SAGE)\n",
    "sage_df_test_mrr = sage_df[sage_df['metricName'] == \"test_mrr\"]\n",
    "sage_df_test_mrr[sage_df_test_mrr['minute_diff'] <=2.01][-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the finetuned model is as close as possible to the mrr of the above training step (GIN)\n",
    "sage_df_fine_test_mrr = sage_df_fine[sage_df_fine['metricName'] == \"test_mrr\"]\n",
    "sage_df_fine_test_mrr[sage_df_fine_test_mrr['metricValue'] >= 0.833613\t] # TODO Change hardcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training time\n",
    "Plotting the training time and especially the intersection points for the equivalent metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(2/0.130118,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(sage_df[sage_df[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"SAGE Reference - Test MRR\",color=\"magenta\",alpha=0.7)\n",
    "sns.lineplot(sage_df_fine_test_mrr[sage_df_fine_test_mrr[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"SAGE Finetuning - Test MRR\",color=\"cyan\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,10)\n",
    "plt.xlabel('Training Time (hours)')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Training Hours for Transfer Learning\")\n",
    "plt.axhline(0.833613,alpha=0.5,color=\"green\",linestyle=\"dashed\",label=\"Test MRR ~ 0.83\")\n",
    "plt.plot(2,0.833613,'ro', markersize=7,color=\"magenta\", markeredgecolor='black', label='Reference - 2 Hour Training')\n",
    "plt.plot(0.130118,0.836982\t,'ro', markersize=7,color=\"cyan\", markeredgecolor='black', label='Finetuning - Intersection Point')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Finetune vs Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gcn_df[gcn_df[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"GCN Reference - Test MRR\",color=\"blue\",alpha=0.7)\n",
    "sns.lineplot(gcn_df_fine[gcn_df_fine[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"GCN Finetuning - Test MRR\",color=\"red\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Reference vs. Finetune \\n Model: GCN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"gcn_fine_vs_reference.pdf\", format='pdf',dpi=5000,bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gin_df[gin_df[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"GIN Reference - Test MRR\",color=\"blue\",alpha=0.7)\n",
    "sns.lineplot(gin_df_fine[gin_df_fine[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"GIN Finetuning - Test MRR\",color=\"red\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Reference vs. Finetune \\n Model: GIN\")\n",
    "plt.legend()\n",
    "plt.savefig(\"gin_fine_vs_reference.pdf\", format='pdf',dpi=5000,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(sage_df[sage_df[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"SAGE Reference - Test MRR\",color=\"blue\",alpha=0.7)\n",
    "sns.lineplot(sage_df_fine[sage_df_fine[\"metricName\"] == \"test_mrr\"],x=\"epoch\",y=\"metricValue\", label=\"SAGE Finetuning - Test MRR\",color=\"red\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Reference vs. Finetune \\n Model: SAGE\")\n",
    "plt.savefig(\"sage_fine_vs_reference.pdf\", format='pdf',dpi=5000,bbox_inches='tight')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation Reference Models\n",
    "Calculation of the standard deviation (model variability) of the gcn reference models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all results\n",
    "experiment_ids = {'GCN arXiv CS Ref 1':'f48a4e67ea8846a0b3d2ca7e674aca95',\n",
    "                  'GCN arXiv CS Ref 2':'c4f5985ba24e4c93b569dde82ce15a78',\n",
    "                  'GCN arXiv CS Ref 3':'942c73672d59449c8a051796ae7f0e49',\n",
    "                  'GCN arXiv CS Ref 4':'54dba56b65814a4fb588b03d32d61cf6',\n",
    "                  'GCN arXiv CS Ref 5':'38ea03024c92483aabcf420fa960d293',\n",
    "                  }\n",
    "workspace = \"swiggy123\"\n",
    "project_name = \"link-prediction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best values from above\n",
    "valid_mrr_values = [0.8484336733818054, 0.8499453663825989, 0.8459517359733582, 0.8498203158378601, 0.8487957119941711]\n",
    "test_mrr_values = [0.844505250453949, 0.8478335738182068, 0.8422207236289978, 0.8466485142707825, 0.8474210500717163]\n",
    "valid_mrr_mean = np.round(np.mean(valid_mrr_values),4)\n",
    "valid_mrr_std = np.round(np.std(valid_mrr_values),4)\n",
    "test_mrr_mean = np.round(np.mean(test_mrr_values),4)\n",
    "test_mrr_std = np.round(np.std(test_mrr_values),4)\n",
    "\n",
    "# get mean valid and test mrr for the 5 runs\n",
    "print(f\"Valid mean MRR: {valid_mrr_mean} ({valid_mrr_std})\")\n",
    "print(f\"Test mean MRR: {test_mrr_mean} ({test_mrr_std})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train val mrr difference over all epochs per run\n",
    "for i in range(0,5):\n",
    "    df_fine_val_train_mrr = experiment_data[i]['metrics']\n",
    "    df_fine_val_train_mrr = df_fine_val_train_mrr[df_fine_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "    print(np.round(np.mean(np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 5 runs with an interval\n",
    "# Combine all runs into a single DataFrame\n",
    "all_metrics = pd.concat([run['metrics'] for run in experiment_data])\n",
    "\n",
    "# Convert metricValue to float\n",
    "all_metrics['metricValue'] = all_metrics['metricValue'].astype(float)\n",
    "\n",
    "# Group by epoch and metricName to calculate mean and std\n",
    "agg_metrics = all_metrics.groupby(['epoch', 'metricName']).agg(\n",
    "    mean_metricValue=('metricValue', 'mean'),\n",
    "    std_metricValue=('metricValue', 'std')\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting train_mrr with std\n",
    "train_mrr = agg_metrics[agg_metrics['metricName'] == 'train_mrr']\n",
    "sns.lineplot(data=train_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"train_mrr\", color=\"green\")\n",
    "plt.fill_between(train_mrr['epoch'], \n",
    "                 train_mrr['mean_metricValue'] - train_mrr['std_metricValue'],\n",
    "                 train_mrr['mean_metricValue'] + train_mrr['std_metricValue'],\n",
    "                 color=\"green\", alpha=0.2)\n",
    "\n",
    "# Plotting valid_mrr with std\n",
    "valid_mrr = agg_metrics[agg_metrics['metricName'] == 'valid_mrr']\n",
    "sns.lineplot(data=valid_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"valid_mrr\", color=\"blue\")\n",
    "plt.fill_between(valid_mrr['epoch'], \n",
    "                 valid_mrr['mean_metricValue'] - valid_mrr['std_metricValue'],\n",
    "                 valid_mrr['mean_metricValue'] + valid_mrr['std_metricValue'],\n",
    "                 color=\"blue\", alpha=0.2)\n",
    "\n",
    "# Plotting valid_mrr with std\n",
    "test_mrr = agg_metrics[agg_metrics['metricName'] == 'test_mrr']\n",
    "sns.lineplot(data=test_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"test_mrr\",linestyle=\"dashed\", color=\"red\")\n",
    "plt.fill_between(test_mrr['epoch'], \n",
    "                 test_mrr['mean_metricValue'] - test_mrr['std_metricValue'],\n",
    "                 test_mrr['mean_metricValue'] + test_mrr['std_metricValue'],\n",
    "                 color=\"red\", alpha=0.2)\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MRR')\n",
    "plt.title('arXiv CS reference GCN - MRR Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN Pretrain':'1f18979244fa4176bead16411753dd65',\n",
    "                  'GIN Pretrain':'98d66fa9995347e1a77ccb90a0116bfd',\n",
    "                  'SAGE Pretrain':'f2551a3b9725426699c4ea698d264510'}\n",
    "workspace = \"tmandelz-outlook-com's Organisation\"\n",
    "project_name = \"transfer-learning-link-prediction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_pretrain = experiment_data[0]['metrics']\n",
    "firstepoch_test_mrr_gcn_pretrain = float(gcn_df_pretrain[gcn_df_pretrain['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = gcn_df_pretrain.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gcn_pretrain = float(gcn_df_pretrain.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "\n",
    "gin_df_pretrain = experiment_data[1]['metrics']\n",
    "firstepoch_test_mrr_gin_pretrain = float(gin_df_pretrain[gin_df_pretrain['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = gin_df_pretrain.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_gin_pretrain = float(gin_df_pretrain.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])\n",
    "\n",
    "sage_df_pretrain = experiment_data[2]['metrics']\n",
    "firstepoch_test_mrr_sage_pretrain = float(sage_df_pretrain[sage_df_pretrain['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "valid_max_idx = sage_df_pretrain.query('metricName == \"valid_mrr\"')[\"metricValue\"].argmax()\n",
    "finalepoch_test_mrr_sage_pretrain = float(sage_df_pretrain.query('metricName == \"test_mrr\"')[\"metricValue\"].iloc[valid_max_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning (Transfer Learning Metrics)\n",
    "Calculation the transfer metrics jumpstar, asymptotic performance and transfer ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mrr_mean is the mean of the best epochs of the reference model\n",
    "jumpstart_test_gcn = firstepoch_test_mrr_gcn_fine - firstepoch_test_mrr_gcn_ref\n",
    "asyperf_test_gcn = finalepoch_test_mrr_gcn_fine - finalepoch_test_mrr_gcn_ref\n",
    "transferratio_test_gcn = (finalepoch_test_mrr_gcn_fine - finalepoch_test_mrr_gcn_ref) / finalepoch_test_mrr_gcn_ref\n",
    "print(f\"GCN: \\nJumpstart: {jumpstart_test_gcn}, Asymptotic Performance: {asyperf_test_gcn}, Transfer Ratio: {transferratio_test_gcn}\")\n",
    "print(f\"Reference: {finalepoch_test_mrr_gcn_ref}, Pretrain: {finalepoch_test_mrr_gcn_pretrain}, Finetune: {finalepoch_test_mrr_gcn_fine}\")\n",
    "\n",
    "jumpstart_test_gin = firstepoch_test_mrr_gin_fine - firstepoch_test_mrr_gin_ref\n",
    "asyperf_test_gin = finalepoch_test_mrr_gin_fine - finalepoch_test_mrr_gin_ref\n",
    "transferratio_test_gin = (finalepoch_test_mrr_gin_fine - finalepoch_test_mrr_gin_ref) / finalepoch_test_mrr_gin_ref\n",
    "print(f\"GIN: \\nJumpstart: {jumpstart_test_gin}, Asymptotic Performance: {asyperf_test_gin}, Transfer Ratio: {transferratio_test_gin}\")\n",
    "print(f\"Reference: {finalepoch_test_mrr_gin_ref}, Pretrain: {finalepoch_test_mrr_gin_pretrain}, Finetune: {finalepoch_test_mrr_gin_fine}\")\n",
    "\n",
    "\n",
    "jumpstart_test_sage = firstepoch_test_mrr_sage_fine - firstepoch_test_mrr_sage_ref\n",
    "asyperf_test_sage = finalepoch_test_mrr_sage_fine - finalepoch_test_mrr_sage_ref\n",
    "transferratio_test_sage = (finalepoch_test_mrr_sage_fine - finalepoch_test_mrr_sage_ref) / finalepoch_test_mrr_sage_ref\n",
    "print(f\"SAGE: \\nJumpstart: {jumpstart_test_sage}, Asymptotic Performance: {asyperf_test_sage}, Transfer Ratio: {transferratio_test_sage}\")\n",
    "print(f\"Reference: {finalepoch_test_mrr_sage_ref}, Pretrain: {finalepoch_test_mrr_sage_pretrain}, Finetune: {finalepoch_test_mrr_sage_fine}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
