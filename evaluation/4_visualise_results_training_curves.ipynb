{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise Results\n",
    "This Notebook downloads experiment data from comet-ml and aggregates or visualises them for the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml.api import API\n",
    "import comet_ml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# set default plt figsize to (12,6)\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "pd.set_option('display.colheader_justify', 'center')\n",
    "# Set default font sizes\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['legend.fontsize'] = 16\n",
    "plt.rcParams['legend.title_fontsize'] = 18\n",
    "\n",
    "\n",
    "# Initialize the Comet API with API key\n",
    "api_key = \"GAzEuNsoYVpPXO2ryeTk7C1o7\"\n",
    "api = API(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiments_results_data(workspace, project_name, experiment_ids):\n",
    "    # Get the list of experiments in the project\n",
    "    result_data = []\n",
    "    for k, v in experiment_ids.items():\n",
    "        experiment = api.get(workspace=workspace,\n",
    "                             project_name=project_name, experiment=v)\n",
    "        print(experiment.id)\n",
    "        print(experiment.name)\n",
    "        # You can also fetch individual metrics, parameters, etc.\n",
    "        metrics_valid_mrr = experiment.get_metrics([\"valid_mrr\"])\n",
    "        metrics_test_mrr = experiment.get_metrics([\"test_mrr\"])\n",
    "        max_valid_mrr_value = float('-inf')\n",
    "        max_epoch = None\n",
    "\n",
    "        for record in metrics_valid_mrr:\n",
    "            metric_value = float(record['metricValue'])\n",
    "            if metric_value > max_valid_mrr_value:\n",
    "                max_valid_mrr_value = metric_value\n",
    "                max_epoch = record['epoch']\n",
    "\n",
    "        print(f\"Max valid_mrr: {max_valid_mrr_value}, Epoch: {max_epoch}\")\n",
    "        for record in metrics_test_mrr:\n",
    "            if record['epoch'] == max_epoch:\n",
    "                metric_test_mrr_epoch = float(record['metricValue'])\n",
    "                break\n",
    "        print(f\"Max test_mrr: {metric_test_mrr_epoch}, Epoch: {max_epoch}\")\n",
    "\n",
    "        result_data.append({\"name\": k, \"key\": experiment.id, \"max_valid_mrr\": max_valid_mrr_value,\n",
    "                           \"test_mrr\": metric_test_mrr_epoch, \"epoch\": max_epoch})\n",
    "\n",
    "    return result_data\n",
    "\n",
    "\n",
    "def plot_training_curves(df_mrr, title=\"MRR Curves\", visualize_test_mrr=True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if visualize_test_mrr:\n",
    "        sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"test_mrr\"], x=\"epoch\",\n",
    "                     y=\"metricValue\", label=\"test_mrr\", linestyle=\"dashed\", color=\"red\", alpha=0.7)\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"train_mrr\", color=\"green\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"valid_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"valid_mrr\", color=\"blue\")\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MRR')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_curves_loss_auc(df_mrr, title=\"MRR Curves\", y_axis=\"Metrics\", ):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_mrr\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"Train MRR\", color=\"blue\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"train_rocauc\"],\n",
    "                 x=\"epoch\", y=\"metricValue\", label=\"AUROC\", color=\"orange\")\n",
    "    sns.lineplot(df_mrr[df_mrr[\"metricName\"] == \"loss_epoch\"], x=\"epoch\",\n",
    "                 y=\"metricValue\", label=\"Negative-Log-\\nLikelihood-Loss\", color=\"green\")\n",
    "\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def get_experiments_data(workspace, project_name, experiment_ids, other_losses=False, epoch_loss=False):\n",
    "    # Get the list of experiments in the project\n",
    "    metrics_data = []\n",
    "    for k, v in experiment_ids.items():\n",
    "        experiment = api.get(workspace=workspace,\n",
    "                             project_name=project_name, experiment=v)\n",
    "        print(experiment.id)\n",
    "        print(experiment.name)\n",
    "        # You can also fetch individual metrics, parameters, etc.\n",
    "        train_mrr = pd.DataFrame(experiment.get_metrics(\"train_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        valid_mrr = pd.DataFrame(experiment.get_metrics(\"valid_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        test_mrr = pd.DataFrame(experiment.get_metrics(\"test_mrr\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "        train_loss = pd.DataFrame(experiment.get_metrics(\"loss_epoch\"))[\n",
    "            ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "\n",
    "        if other_losses:\n",
    "            valid_loss = pd.DataFrame(experiment.get_metrics(\"valid_loss\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            test_loss = pd.DataFrame(experiment.get_metrics(\"test_loss\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            metrics = pd.concat(\n",
    "                [train_mrr, valid_mrr, test_mrr, train_loss, valid_loss, test_loss])\n",
    "        elif epoch_loss:\n",
    "            epoch_loss = pd.DataFrame(experiment.get_metrics(\"loss_epoch\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            auc = pd.DataFrame(experiment.get_metrics(\"train_rocauc\"))[\n",
    "                ['metricName', 'metricValue', 'epoch', 'timestamp']]\n",
    "            metrics = pd.concat(\n",
    "                [train_mrr, valid_mrr, test_mrr, epoch_loss, auc])\n",
    "        else:\n",
    "            metrics = pd.concat([train_mrr, valid_mrr, test_mrr, train_loss])\n",
    "        metrics_data.append(\n",
    "            {\"name\": k, \"key\": experiment.id, \"metrics\": metrics})\n",
    "    return metrics_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduction Models\n",
    "Model data for reproduction models is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'reproduction_ogbl-citation2_repo_parameter':'832b085db0fb4fc6802da9b714c86072',}\n",
    "workspace = \"link-prediction-reproduction\"\n",
    "project_name = \"link-prediction-reproduction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids,epoch_loss=True)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repro_val_train_mrr = experiment_data[0]['metrics']\n",
    "df_repro_val_train_mrr = df_repro_val_train_mrr[df_repro_val_train_mrr[\"metricName\"].isin([\"train_mrr\", \"valid_mrr\"])]\n",
    "np.round(np.mean(np.array(df_repro_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'], dtype=float) - np.array(\n",
    "    df_repro_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'], dtype=float)), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUROC, MRR and NLL-Loss\n",
    "Plot AUROC, MRR and NLL-Loss together into a single visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repro_df = experiment_data[0]['metrics']\n",
    "repro_df['metricValue'] = repro_df['metricValue'].astype(float)\n",
    "plot_training_curves_loss_auc(repro_df, \"Training MRR, AUROC and \\nNegative-Log-Likelihood Loss for reproduction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Models\n",
    "Model data for reference models (gcn and ngcn) is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN arXiv CS reference':'c4f5985ba24e4c93b569dde82ce15a78',\n",
    "                  'NGCN arXiv CS reference':'d45ca57aa4d84332abe8a2a994302ca1'}\n",
    "workspace = \"swiggy123\"\n",
    "project_name = \"link-prediction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELSELECTION for GCN arXiv CS reference\n",
    "df_ = experiment_data[0]['metrics']\n",
    "df_[(df_['epoch'].isin([2070,2080])) & (df_['metricName'] == \"valid_mrr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get best \n",
    "gcn_df = experiment_data[0]['metrics']\n",
    "\n",
    "firstepoch_test_mrr_gcn_ref = float(gcn_df[gcn_df['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "finalepoch_test_mrr_gcn_ref = float(gcn_df[gcn_df['metricName'] == \"test_mrr\"].iloc[2071]['metricValue'])\n",
    "\n",
    "ngcn_df = experiment_data[1]['metrics']\n",
    "\n",
    "firstepoch_test_mrr_ngcn_ref = float(ngcn_df[ngcn_df['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "finalepoch_test_mrr_ngcn_ref = float(ngcn_df[ngcn_df['metricName'] == \"test_mrr\"].iloc[1983]['metricValue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref_val_train_mrr =experiment_data[0]['metrics']\n",
    "df_ref_val_train_mrr = df_ref_val_train_mrr[df_ref_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "np.round(np.mean(np.array(df_ref_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_ref_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MRR Curves\n",
    "Plot MRR Curves together into a single visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df['metricValue'] = gcn_df['metricValue'].astype(float)\n",
    "ngcn_df['metricValue'] = ngcn_df['metricValue'].astype(float)\n",
    "plot_training_curves(gcn_df, \"arXiv CS Reference GCN - MRR Curves\")\n",
    "plot_training_curves(ngcn_df, \"arXiv CS Reference NGCN - MRR Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain Models\n",
    "Model data for Pretrain models is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN arXiv w/o CS Pretraining':'23f4e7d8ec4c40f6a9852a33808a4515',\n",
    "                  'NGCN arXiv w/o CS Pretraining':'d3ca1509073d4ce3999cad340d610cb3'}\n",
    "\n",
    "workspace = \"swiggy123\"\n",
    "project_name = \"link-prediction-pretraining\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pretrain_val_train_mrr =experiment_data[0]['metrics']\n",
    "df_pretrain_val_train_mrr = df_pretrain_val_train_mrr[df_pretrain_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "np.round(np.mean(np.array(df_pretrain_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_pretrain_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELSELECTION for GCN arXiv w/o CS Pretraining\n",
    "df_ = experiment_data[0]['metrics']\n",
    "df_[(df_['epoch'].isin([200,195])) & (df_['metricName'] == \"valid_mrr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELSELECTION for NGCN arXiv w/o CS Pretraining\n",
    "df_ = experiment_data[1]['metrics']\n",
    "df_[(df_['epoch'].isin([180,175])) & (df_['metricName'] == \"valid_mrr\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_pretrain = experiment_data[0]['metrics']\n",
    "ngcn_df_pretrain = experiment_data[1]['metrics']\n",
    "\n",
    "gcn_df_pretrain['metricValue'] = gcn_df_pretrain['metricValue'].astype(float)\n",
    "ngcn_df_pretrain['metricValue'] = ngcn_df_pretrain['metricValue'].astype(float)\n",
    "plot_training_curves(gcn_df_pretrain, \"arXiv w/o CS Pretrain GCN - MRR Curves\",False)\n",
    "plot_training_curves(ngcn_df_pretrain, \"arXiv w/o CS Pretrain NGCN - MRR Curves\",False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning Models\n",
    "Model data for Finetuning models is downloaded and visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_ids = {'GCN arXiv CS Finetuning':'50b1b190160c4e1185fca9d8f815d83a',\n",
    "                  'NGCN arXiv CS Finetuning':'ddfef4f15cc34101b030dabcd970aed8'}\n",
    "workspace = \"swiggy123\"\n",
    "project_name = \"link-prediction-finetuning\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Difference Validation and Train MRR\n",
    "Calculate the mean difference from validation to train MRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_val_train_mrr =experiment_data[0]['metrics']\n",
    "df_fine_val_train_mrr = df_fine_val_train_mrr[df_fine_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "np.round(np.mean(np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELSELECTION for GCN arXiv CS Finetuning\n",
    "df_ = experiment_data[0]['metrics']\n",
    "df_[(df_['epoch'].isin([1900,1800])) & (df_['metricName'] == \"valid_mrr\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELSELECTION for NGCN arXiv CS Finetuning\n",
    "df_ = experiment_data[1]['metrics']\n",
    "df_[(df_['epoch'].isin([1900,1800])) & (df_['metricName'] == \"valid_mrr\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot MRR Curves\n",
    "Plot MRR Curves together into a single visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_fine = experiment_data[0]['metrics']\n",
    "firstepoch_test_mrr_gcn_fine = float(gcn_df_fine[gcn_df_fine['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "finalepoch_test_mrr_gcn_fine = float(gcn_df_fine[gcn_df_fine['metricName'] == \"test_mrr\"].iloc[1896]['metricValue'])\n",
    "\n",
    "ngcn_df_fine = experiment_data[1]['metrics']\n",
    "firstepoch_test_mrr_ngcn_fine = float(ngcn_df_fine[ngcn_df_fine['metricName'] == \"test_mrr\"].iloc[0]['metricValue'])\n",
    "finalepoch_test_mrr_ngcn_fine = float(ngcn_df_fine[ngcn_df_fine['metricName'] == \"test_mrr\"].iloc[1397]['metricValue'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df_fine['metricValue'] = gcn_df_fine['metricValue'].astype(float)\n",
    "ngcn_df_fine['metricValue'] = ngcn_df_fine['metricValue'].astype(float)\n",
    "plot_training_curves(gcn_df_fine, \"arXiv CS Finetuning GCN - MRR Curves\")\n",
    "plot_training_curves(ngcn_df_fine, \"arXiv CS Finetuning NGCN - MRR Curves\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Time Differences GCN Reference / Finetune\n",
    "Computing time differences between the reference and finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_df['timestamp'] = gcn_df['timestamp']/1000\n",
    "gcn_df['timestamp'] = pd.to_datetime(gcn_df['timestamp'], unit='s')\n",
    "gcn_df['minute_diff'] = (gcn_df['timestamp'] - gcn_df['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "gcn_df_fine['timestamp'] = gcn_df_fine['timestamp']/1000\n",
    "gcn_df_fine['timestamp'] = pd.to_datetime(gcn_df_fine['timestamp'], unit='s')\n",
    "gcn_df_fine['minute_diff'] = (gcn_df_fine['timestamp'] - gcn_df_fine['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "ngcn_df['timestamp'] = ngcn_df['timestamp']/1000\n",
    "ngcn_df['timestamp'] = pd.to_datetime(ngcn_df['timestamp'], unit='s')\n",
    "ngcn_df['minute_diff'] = (ngcn_df['timestamp'] - ngcn_df['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60\n",
    "\n",
    "ngcn_df_fine['timestamp'] = ngcn_df_fine['timestamp']/1000\n",
    "ngcn_df_fine['timestamp'] = pd.to_datetime(ngcn_df_fine['timestamp'], unit='s')\n",
    "ngcn_df_fine['minute_diff'] = (ngcn_df_fine['timestamp'] - ngcn_df_fine['timestamp'].iloc[0]).dt.total_seconds() / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the reference model was the first time over 10 hours (GCN)\n",
    "gcn_df_test_mrr = gcn_df[gcn_df['metricName'] == \"test_mrr\"]\n",
    "gcn_df_test_mrr[gcn_df_test_mrr['minute_diff'] <=10.01][-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the reference model was the first time over 10 hours (NGCN)\n",
    "ngcn_df_test_mrr = ngcn_df[ngcn_df['metricName'] == \"test_mrr\"]\n",
    "ngcn_df_test_mrr[ngcn_df_test_mrr['minute_diff'] <=10.01][-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the finetuned model is as close as possible to the mrr of the above training step (GCN)\n",
    "gcn_df_fine_test_mrr = gcn_df_fine[gcn_df_fine['metricName'] == \"test_mrr\"]\n",
    "gcn_df_fine_test_mrr[gcn_df_fine_test_mrr['metricValue'] >= 0.823472][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training step where the finetuned model is as close as possible to the mrr of the above training step (NGCN)\n",
    "ngcn_df_fine_test_mrr = ngcn_df_fine[ngcn_df_fine['metricName'] == \"test_mrr\"]\n",
    "ngcn_df_fine_test_mrr[ngcn_df_fine_test_mrr['metricValue'] >= 0.860385]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training time\n",
    "Plotting the training time and especially the intersection points for the equivalent metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(gcn_df[gcn_df[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"GCN Reference - Test MRR\",color=\"blue\",alpha=0.7)\n",
    "sns.lineplot(gcn_df_fine[gcn_df_fine[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"GCN Finetuning - Test MRR\",color=\"red\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Training Time (hours)')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Training Hours for Transfer Learning\")\n",
    "plt.axhline(0.823472,alpha=0.5,color=\"green\",linestyle=\"dashed\",label=\"Test MRR ~ 0.82\")\n",
    "plt.plot(10,0.823472,'ro', markersize=7,color=\"blue\", markeredgecolor='black', label='Reference - 10 Hour Training')\n",
    "plt.plot(2.267009,0.823030,'ro', markersize=7,color=\"red\", markeredgecolor='black', label='Finetuning - Intersection Point')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(ngcn_df[ngcn_df[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"NGCN Reference - Test MRR\",color=\"blue\",alpha=0.7)\n",
    "sns.lineplot(ngcn_df_fine[ngcn_df_fine[\"metricName\"] == \"test_mrr\"],x=\"minute_diff\",y=\"metricValue\", label=\"NGCN Finetuning - Test MRR\",color=\"red\",alpha=0.7)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('Training Time (hours)')\n",
    "plt.ylabel('Test MRR')\n",
    "plt.title(\"Comparison of Training Hours for Transfer Learning\")\n",
    "plt.axhline(0.860385,alpha=0.5,color=\"green\",linestyle=\"dashed\",label=\"Test MRR ~ 0.86\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation Reference Models\n",
    "Calculation of the standard deviation (model variability) of the gcn reference models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all results\n",
    "experiment_ids = {'GCN arXiv CS Ref 1':'f48a4e67ea8846a0b3d2ca7e674aca95',\n",
    "                  'GCN arXiv CS Ref 2':'c4f5985ba24e4c93b569dde82ce15a78',\n",
    "                  'GCN arXiv CS Ref 3':'942c73672d59449c8a051796ae7f0e49',\n",
    "                  'GCN arXiv CS Ref 4':'54dba56b65814a4fb588b03d32d61cf6',\n",
    "                  'GCN arXiv CS Ref 5':'38ea03024c92483aabcf420fa960d293',\n",
    "                  }\n",
    "workspace = \"swiggy123\"\n",
    "project_name = \"link-prediction\"\n",
    "\n",
    "experiment_data = get_experiments_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)\n",
    "results_data = get_experiments_results_data(workspace=workspace,project_name=project_name,experiment_ids=experiment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best values from above\n",
    "valid_mrr_values = [0.8484336733818054, 0.8499453663825989, 0.8459517359733582, 0.8498203158378601, 0.8487957119941711]\n",
    "test_mrr_values = [0.844505250453949, 0.8478335738182068, 0.8422207236289978, 0.8466485142707825, 0.8474210500717163]\n",
    "valid_mrr_mean = np.round(np.mean(valid_mrr_values),4)\n",
    "valid_mrr_std = np.round(np.std(valid_mrr_values),4)\n",
    "test_mrr_mean = np.round(np.mean(test_mrr_values),4)\n",
    "test_mrr_std = np.round(np.std(test_mrr_values),4)\n",
    "\n",
    "# get mean valid and test mrr for the 5 runs\n",
    "print(f\"Valid mean MRR: {valid_mrr_mean} ({valid_mrr_std})\")\n",
    "print(f\"Test mean MRR: {test_mrr_mean} ({test_mrr_std})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train val mrr difference over all epochs per run\n",
    "for i in range(0,5):\n",
    "    df_fine_val_train_mrr = experiment_data[i]['metrics']\n",
    "    df_fine_val_train_mrr = df_fine_val_train_mrr[df_fine_val_train_mrr[\"metricName\"].isin([\"train_mrr\",\"valid_mrr\"])]\n",
    "    print(np.round(np.mean(np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['valid_mrr'],dtype=float) - np.array(df_fine_val_train_mrr.pivot(columns=[\"metricName\"])['metricValue']['train_mrr'],dtype=float)),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 5 runs with an interval\n",
    "# Combine all runs into a single DataFrame\n",
    "all_metrics = pd.concat([run['metrics'] for run in experiment_data])\n",
    "\n",
    "# Convert metricValue to float\n",
    "all_metrics['metricValue'] = all_metrics['metricValue'].astype(float)\n",
    "\n",
    "# Group by epoch and metricName to calculate mean and std\n",
    "agg_metrics = all_metrics.groupby(['epoch', 'metricName']).agg(\n",
    "    mean_metricValue=('metricValue', 'mean'),\n",
    "    std_metricValue=('metricValue', 'std')\n",
    ").reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting train_mrr with std\n",
    "train_mrr = agg_metrics[agg_metrics['metricName'] == 'train_mrr']\n",
    "sns.lineplot(data=train_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"train_mrr\", color=\"green\")\n",
    "plt.fill_between(train_mrr['epoch'], \n",
    "                 train_mrr['mean_metricValue'] - train_mrr['std_metricValue'],\n",
    "                 train_mrr['mean_metricValue'] + train_mrr['std_metricValue'],\n",
    "                 color=\"green\", alpha=0.2)\n",
    "\n",
    "# Plotting valid_mrr with std\n",
    "valid_mrr = agg_metrics[agg_metrics['metricName'] == 'valid_mrr']\n",
    "sns.lineplot(data=valid_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"valid_mrr\", color=\"blue\")\n",
    "plt.fill_between(valid_mrr['epoch'], \n",
    "                 valid_mrr['mean_metricValue'] - valid_mrr['std_metricValue'],\n",
    "                 valid_mrr['mean_metricValue'] + valid_mrr['std_metricValue'],\n",
    "                 color=\"blue\", alpha=0.2)\n",
    "\n",
    "# Plotting valid_mrr with std\n",
    "test_mrr = agg_metrics[agg_metrics['metricName'] == 'test_mrr']\n",
    "sns.lineplot(data=test_mrr, x=\"epoch\", y=\"mean_metricValue\", label=\"test_mrr\",linestyle=\"dashed\", color=\"red\")\n",
    "plt.fill_between(test_mrr['epoch'], \n",
    "                 test_mrr['mean_metricValue'] - test_mrr['std_metricValue'],\n",
    "                 test_mrr['mean_metricValue'] + test_mrr['std_metricValue'],\n",
    "                 color=\"red\", alpha=0.2)\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MRR')\n",
    "plt.title('arXiv CS reference GCN - MRR Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning (Transfer Learning Metrics)\n",
    "Calculation the transfer metrics jumpstar, asymptotic performance and transfer ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mrr_mean is the mean of the best epochs of the reference model\n",
    "jumpstart_test_gcn = firstepoch_test_mrr_gcn_fine - firstepoch_test_mrr_gcn_ref\n",
    "asyperf_test_gcn = finalepoch_test_mrr_gcn_fine - test_mrr_mean\n",
    "transferratio_test_gcn = (finalepoch_test_mrr_gcn_fine - test_mrr_mean) / test_mrr_mean\n",
    "\n",
    "jumpstart_test_ngcn =  firstepoch_test_mrr_ngcn_fine - firstepoch_test_mrr_ngcn_ref\n",
    "asyperf_test_ngcn = finalepoch_test_mrr_ngcn_fine - finalepoch_test_mrr_ngcn_ref\n",
    "transferratio_test_ngcn = (finalepoch_test_mrr_ngcn_fine - finalepoch_test_mrr_ngcn_ref) / finalepoch_test_mrr_ngcn_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Visualisations\n",
    "Further visualisations used for the thesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(path_mrr_curves,title=\"MRR Curves\",visualize_test_mrr =True):\n",
    "    with open(path_mrr_curves, 'r') as f:\n",
    "        arxiv_cs_mrr_data = json.load(f)\n",
    "    arxiv_cs_mrr_df = pd.DataFrame(arxiv_cs_mrr_data)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for curve in range(len(arxiv_cs_mrr_df)):\n",
    "        if visualize_test_mrr and arxiv_cs_mrr_df.iloc[curve]['name'] == \"test_mrr\":\n",
    "            plt.plot(arxiv_cs_mrr_df.iloc[curve]['x'], arxiv_cs_mrr_df.iloc[curve]['y'], label=arxiv_cs_mrr_df.iloc[curve]['name'],linestyle=\"dashed\",color=\"red\",alpha=0.7)\n",
    "        elif arxiv_cs_mrr_df.iloc[curve]['name'] == \"train_mrr\":\n",
    "            plt.plot(arxiv_cs_mrr_df.iloc[curve]['x'], arxiv_cs_mrr_df.iloc[curve]['y'], label=arxiv_cs_mrr_df.iloc[curve]['name'],color =\"green\")\n",
    "        elif arxiv_cs_mrr_df.iloc[curve]['name'] == \"valid_mrr\":\n",
    "            plt.plot(arxiv_cs_mrr_df.iloc[curve]['x'], arxiv_cs_mrr_df.iloc[curve]['y'], label=arxiv_cs_mrr_df.iloc[curve]['name'],color =\"blue\")\n",
    "\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MRR')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves('./training_curve_data/finetuning_reference_hyperparameters_tuned.json',\"MRR Curves - Finetuning\",True)\n",
    "plot_training_curves('./training_curve_data/arxiv_cs_mrr_curves.json')\n",
    "plot_training_curves('./training_curve_data/pretraining_mrr_curves.json',\"GCN MRR Curves Pretraining\",visualize_test_mrr=False)\n",
    "plot_training_curves('./training_curve_data/reproduction_mrr_curve.json',\"MRR Curves Reproduction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
