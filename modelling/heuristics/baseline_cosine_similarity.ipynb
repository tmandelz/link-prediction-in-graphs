{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory: c:\\Users\\User\\link-prediction-in-graphs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "import matplotlib.pyplot as plt\n",
    "from ogb.linkproppred import Evaluator\n",
    "import sys\n",
    "sys.path.append('modelling/')\n",
    "import random\n",
    "import os\n",
    "if os.path.basename(os.getcwd()) != 'link-prediction-in-graphs':\n",
    "    parent_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "    os.chdir(parent_dir)\n",
    "from comet_ml import Experiment\n",
    "from modelling.dataset_split.dataset_splitter import Dataset_Splitter\n",
    "\n",
    "import os\n",
    "print(f\"current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_split(dataset_selected = \"ogbn-papers100M\"):\n",
    "    ds_split = Dataset_Splitter()\n",
    "    dataset = ds_split.load_dataset(dataset_selected)\n",
    "    split_edge, _ = ds_split.get_edges_split(dataset)\n",
    "    n_samples = len(split_edge[\"valid\"][\"source_node\"])\n",
    "    random_sampled_train = random.sample(range(len(split_edge[\"train\"][\"source_node\"])),k=n_samples)\n",
    "    split_edge[\"train\"][\"source_node\"] = split_edge[\"train\"][\"source_node\"][random_sampled_train]\n",
    "    split_edge[\"train\"][\"target_node\"] = split_edge[\"train\"][\"target_node\"][random_sampled_train]\n",
    "    split_edge[\"train\"][\"target_node_neg\"] = [random.sample(range(split_edge[\"train\"][\"target_node\"].max()),k=1000) for x in range(n_samples)]\n",
    "    split_edge[\"train\"][\"target_node_neg\"] = torch.tensor(split_edge[\"train\"][\"target_node_neg\"])\n",
    "    return split_edge,dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cosine Similarity and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mrr_cosine(split_edge,dataset,split:str=\"valid\"):\n",
    "\n",
    "    pred_pos_df = pd.DataFrame((split_edge[split][\"source_node\"],split_edge[split][\"target_node\"])).T.rename(columns={0:\"source\",1:\"target\"})\n",
    "    def calc_cosine(source, target, node_features):\n",
    "        return cosine_similarity(node_features[source].reshape(1, -1), node_features[target].reshape(1, -1))[0][0]\n",
    "\n",
    "\n",
    "    node_features = dataset[0].x\n",
    "    pred_pos_df['cosine_similarity'] = pred_pos_df.apply(lambda row: calc_cosine(row['source'], row['target'], node_features), axis=1)\n",
    "    pred_neg_df = pd.DataFrame({'source': split_edge[split][\"source_node\"].view(-1, 1).repeat(1, 1000).view(-1), 'target': split_edge[split][\"target_node_neg\"].view(-1)})\n",
    "    \n",
    "    # calc cosine similarity\n",
    "    ddf = dd.from_pandas(pred_neg_df, npartitions=64)\n",
    "    def calc_cosine_row(row):\n",
    "        return calc_cosine(row['source'], row['target'], node_features)\n",
    "    ddf['cosine_similarity'] = ddf.apply(calc_cosine_row, axis=1, meta=('float'))\n",
    "    pred_neg_df = ddf.compute(scheduler=get)\n",
    "    evaluator = Evaluator(name='ogbl-citation2')\n",
    "    eval_dict = evaluator.eval({\n",
    "                'y_pred_pos': torch.tensor(pred_pos_df[\"cosine_similarity\"].values),\n",
    "                'y_pred_neg': torch.tensor(pred_neg_df[\"cosine_similarity\"].values).view(-1,1000),\n",
    "            })\n",
    "    return eval_dict[\"mrr_list\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_and_save_baseline_cosine(dataset_name):\n",
    "    edge_split,dataset = get_edge_split(dataset_name)\n",
    "    train_mrr = calc_mrr_cosine(edge_split,dataset,\"train\")\n",
    "    valid_mrr = calc_mrr_cosine(edge_split,dataset,\"valid\")\n",
    "    test_mrr = calc_mrr_cosine(edge_split,dataset,\"test\")\n",
    "    experiment = Experiment(\n",
    "                    api_key=\"fMjtHh9OnnEygtraNMjP7Wpig\",\n",
    "                    project_name=\"link-prediction-baselines\",\n",
    "                    workspace=\"swiggy123\"\n",
    "                )\n",
    "    experiment.set_name(f\"cosine_similarity_{dataset_name}\")\n",
    "\n",
    "    metrics = {\n",
    "            \"train_mrr\": train_mrr,\n",
    "            \"valid_mrr\": valid_mrr,\n",
    "            \"test_mrr\": test_mrr}\n",
    "    experiment.log_metrics(metrics)\n",
    "    experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ogbn-papers100M has been updated.\n",
      "Creating Splits for dataset ogbn-papers100M\n",
      "Returning Splits for dataset ogbn-papers100M\n"
     ]
    }
   ],
   "source": [
    "calc_and_save_baseline_cosine(\"ogbn-papers100M\")\n",
    "calc_and_save_baseline_cosine(\"ogbn-arxiv\")\n",
    "calc_and_save_baseline_cosine(\"ogbl-citation2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
